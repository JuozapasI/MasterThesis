In this chapter I will provide general review of single cell transcriptomics and related challenges.

\section{Introduction to single cell transcriptomics}

Cells are the fundamental units of life, forming the basis of all living organisms.
One of the major goals of biology is to understand cellular systems and the processes occurring within cells.
Since the discovery of the DNA structure in 1953 and the development of the conceptual framework for genetic information
transfer, scientists have made significant efforts to sequence the genomes of various organisms.
This led to the development of the first sequencing methods, such as Sanger sequencing in 1975,
which laid the foundation for next-generation sequencing technologies in use today,
including the widely used Illumina platform (\cite{Heather2016}).
Current sequencing methods allow us to obtain the complete genetic sequence of any organism.
However, the genome alone cannot explain the full diversity of cells in multicellular organisms,
as all cells share the same genome but exhibit significant variation in shape, size, and function.

RNA sequencing (RNAseq), on the other hand, enables the measurement of gene expression within cells,
providing valuable insights into cellular processes.
RNAseq methods largely follow DNA sequencing protocols,
with the addition of a step where complementary DNA (cDNA) is synthesized from RNA (\cite{Heumos2023}).
The first RNAseq methods were developed for bulk sequencing, where RNA from entire cell populations is sequenced,
providing an average gene expression profile across the population.
Although bulk RNAseq provided valuable insights into the dynamics of cellular processes
(such as changes in disease states in response to therapeutics, detection of gene isoforms, gene fusions,
and various other properties of target cells (\cite{Heumos2023})),
this approach masks non-dominant processes and cell-to-cell variability through averaging.
This limitation was addressed by the introduction of single-cell RNA sequencing (scRNAseq) methods,
which allow the generation of transcriptomic profiles from individual cells,
providing high-resolution insights into cellular systems.

Current scRNAseq methods enable the generation of transcriptomic profiles from thousands of cells
at unprecedented resolution in a single experiment.
These data can be used for constructing cellular atlases (\cite{Rozenblatt2017}),
understanding disease mechanisms (\cite{Zhang2024}),
exploring cell differentiation and developmental processes (\cite{Skinner2024}), and many other applications.

\section{Key methods and technologies in scRNAseq}

\subsection{Key methods}

All scRNAseq protocols share these main three steps:
isolation of single cells, library preparation and sequencing (\cite{Andrews2018}).

The first step is mainly done in two ways:
either by placing cells in separate droplets (microfluidics approach),
or by separating cells into different wells (plate-based approach).

The next generation sequencing (NGS) usually requires nanograms or more of DNA,
and the RNA content in single cells is far from this amount (\cite{Wu2017}).
Consequently, before sequencing, reverse transcription (RT) and amplification is needed.

Finally, the prepared library is sequenced using NGS methods.
The most popular is ........

\subsection{Current scRNAseq Platforms}

As mentioned before, scRNAseq methods mainly can be grouped in two groups: droplet-based and plate-based.

Droplet-based methods (e.g. inDrops (\cite{Klein2015}), Drop-seq (\cite{Macosko2015}),
Chromium by 10X Genomics (\cite{Zheng2017}))
separate cells by placing them into different droplets, containing hidrogel primers and lysis mix.
Primers usually share common structure, including barcode sequenes, unique molecular identifiers (UMIs),
PCR handlers and poly-T (\cite{Zhang2019}).
Cell barcodes are sequences used for determining the cell from which particular read sequenced
(in sequencing step, content from all droplets is mixed and sequenced at once).
UMIs are used to quantify real amount of RNA in cells
(after amplification, more than one copy of each captured RNA is present).
PCR handlers are used for the amplification, while poly-T are used for capturing RNAs.
Example of primer design can be seen in figure \ref{fig:primer}).
Once cells are in the droplets, cell lysis takes place, RNAs escapes cells and are captured by primers.
Depending on method,
reverse transcription either takes place directly in the droplets (inDrops, 10X) or after demulsification (Drop-seq).
Next steps usually include RNA fragmentation and PCR amplification, followed by NGS.

Droplet-based methods are high-throughput
(current microfluidic devices are able to generate thousands of above described droplets per second (\cite{Prakadan2017})),
cost-effective, but have low detection rates compared to other methods and
captures only 3' (or 5') ends of transcripts (\cite{Heumos2023}).
Capturing only 3' ends of transcripts might be not a problem when trying to identify cell populations,
however, it masks such processes as splicing variants, thus should be considered carefully while planning experiments.

Plate-based methods (e.g. CEL-Seq2 (\cite{Hashimshony2016}), Smart-seq2 (\cite{Picelli2013}))
separate cells by placing them into different microwells on a plate.
Before this, cells can be sorted using ,for example, fluorescent-activated cell sorting (FACS) (\cite{Heumos2023}).
Similarly to droplets, microwells contain lysis buffers and RT mix,
and these processes are followed by amplification and NGS (\cite{Hashimshony2016}).
Barcodes can be integrated into reverse transcription step similarly as in droplet case.

Overall, plate-based methods have lower throughput, might be more costly and labor-intensive,
but offers recovery of many genes per cell, allows prior sorting and
(for some protocols) it is possible to sequence full transcripts (\cite{Heumos2023}).

In the next sections, we will focus on the droplet-based approaches,
as all the data used in this thesis is generated by droplet-based methods.

\section{Data quality and challenges in scRNAseq data}

The quality of scRNAseq data

\subsection{Noise}

The noise present in the scRNAseq data can be either biological or technical.

\subsection{Dimentionality}

\section{Computational tools and analytical approaches}

\subsection{Raw data processing}

The output of the typical scRNAseq experiment is FASTQ files, containing recorded sequences,
as well as (depending on method) barcode and UMI sequences and quality scores.
The subsequent processing steps include quality control of FASTQ file (is done based on quality scores),
filtering dublicate reads (using UMIs), mapping reads to the genome sequence and assigning the reads to the genes,
and, finally, counting gene expression per cell (barcode) (\cite{Heumos2023}) (see figure \ref{fig:rawData}).
Usually, all these steps are done with single piece of dedicated software,
such as STARsolo (\cite{Kaminow2021}), CellRanger (\cite{Zheng2017}) or other.
It should be noted, that there are variations in the above described pipeline,
depending on many experiment-related (e.g., if there is known genome sequence or transcriptone of the study organism),
or method-related (e.g., if UMIs are used in the protocol) factors.
The typical result of such processing is cell-gene matrix (i.e. a matrix with cells as rows, genes as columns,
and the entries being the number of captured RNAs in the particular cell coresponding to particular gene).

\subsection{Preprocessing of count matrices}

Preprocessing of count matrices usually involves such steps:
quality control, normalization and feature selection.

Quality of indidual cells can be evaluated based on several factors, such as mitochondrial gene contents
(apoptotic cells tend to have high proportion of mitochondrial genes (\cite{Heumos2023})) or
total number of captured genes (very low numbers can be produced by empty droplets).
Also, in some cases, two cells can end up in one droplet,
resulting count matrix entry corresponding to genes from  both cells.
Such matrix entries (doublets) can be filtered by using specialized software
such Scrublet (\cite{Wolock2019}) or scDblFinder (\cite{Germain2022}).
Ambient RNA is another aspect, increasing noise in the scRNAseq data.
It is the RNA that escapes individual droplets and spreads in the medium and other droplets,
causing some background noise.
Even though the amount of such RNA is not high (give some numbers and citation),
cleaning count matrices from such RNAs can increase quality of the data.
This can be done by finding out background noise profile from the empty droplets and correcting count matrix accordingly.
There are dedicated softwares,
such as SoupX (\cite{Young2020}), decontX (\cite{Yang2020}), CellBender (\cite{Fleming2023}) and others.

The next step in preprocessing pipeline is normalization.
The aim of it is to transform the data such that variantion in gene expression levels is similar,
so that subsequent analysis would be more efficient (\cite{Ahlmann2023}).
Also, it might help to remove some biases,
such as sequencing depth in the case of combining data from several samples (\cite{Lingen2024}).
There are plenty of methods for normalization, based on various approaches
(e.g. delta-method-based, residual-based, latent gene expression-based, count-based (\cite{Ahlmann2023})).
Therefore, one should carefully choose the normalization method, based on the individual experiment design.
General recomendations for normalization suggest comparing several methods and if the results are similar,
to use the simpler method (\cite{Lingen2024}).
Sophisticated methods doesn't necessarily show better results, and recent benchmarking study (\cite{Ahlmann2023})
has showed that such simple method (particularly the logarithm normalization,
where each element $y$ of count matrix is transformed by formula $y_{trnasformed} = log(y+1)$)
performs as well or better than more advanced methods.

When the data is normalized and cleaned, one can get rid of not informative genes.
Initially, count matrices contain all the genes that were present in the transcriptome.
However, not all of them are expressed in the sequenced data, or are expressed in negligable numbers (\cite{Heumos2023}).
Therefore, it is common practice to filter such genes (e.g., genes that are expressed in less than 3 cells).
Moreover, some genes might be expressed in all the cells more or less evenly (housekeeping genes),
and thus don't provide information that could be usefull in, for instance, grouping cells or determining cell types.
Therefore, in many applications, it is beneficial to leave only those genes, that are highly variable between cells.
In such way, the dimensionality of the count matrix is greatly reduced without loosing significant information.
Additionally, one can filter out those genes that are out of scope of indicidual study.

\subsection{Dimensionality reduction}

Even after filtering and selecting only highly variable genes, there are usually left several thousand genes.
It is not possible to visualize (and interpret in general) data of such high dimentionality, therefore,
dimensionality reduction is needed.

\subsection{Clustering and other stuff}

\section{Enhancing scRNAseq data}

\section{Deriving useful information from scRNAseq data}

\section{Current limitations and future perspectives}

